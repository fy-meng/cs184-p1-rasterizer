<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
    <style>
        body {
            padding: 100px;
            width: 1000px;
            margin: auto;
            text-align: left;
            font-weight: 300;
            font-family: 'Open Sans', sans-serif;
            color: #121212;
        }

        h1, h2, h3, h4 {
            font-family: 'Source Sans Pro', sans-serif;
        }
    </style>
    <title>CS 184 Rasterizer</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});














































    </script>
    <script type="text/javascript"
            src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>

<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2019</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Fanyu Meng, CS184-adh</h2>

<br><br>

<h2 align="middle">Overview</h2>
<p>In this project, we built a crude rasterizer based on triangles. We can use triangles to create a picture, or
    apply textures to a surface give a transform between the image coordinate and the texture coordinate. We also
    applied some antialiasing methods for sampling, in both basic triangle rendering and texture sampling.</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

<p>The way we rasterize a triangle is as follows: </p>

<ol>
    <li>Find the bounding box of the triangle. The bounding box is defined as the rectangle from <code>(x_min,
        y_min)</code> to <code>(x_max, y_max)</code>. <code>x_min</code> is the minimum x coordinate of the
        vertices, rounding down to the nearest integer; <code>x_max</code> is the maximum x coordinate rounding up.
        Same thing applies to the y coordinate;
    </li>
    <li>For each pixel center in the bounding box, we test if the point is in the triangle using the naive normal
        vector method or using Barycentric coordinates;
    </li>
    <li>If the point is in the triangle, we send the according color to the frame buffer. This color could be a
        given color or sampled from a texture.
    </li>
</ol>

<p>
    The runtime of the algorithm is $O(NW_\text{max}H_\text{max})$, where $N$ is the number of triangles,
    $H_\text{max}$ and $H_\text{max}$ is the maximum width and height of the bounding boxes of the triangles since
    we are going through every pixel in each of the bounding boxes.
</p>

<div align="middle">
    <img src="images/p1_rasterization.png" align="middle" width="30%"/>
    <figcaption align="middle">Aliases while using the default settings.</figcaption>
</div>

<p>
    We optimized the algorithm by changing the naive point in triangle test using Barycentric coordinates. Since
    $\alpha + \beta + \gamma = 1$ in Barycentric coordinates, we don't need to compute $\gamma$ directly and roughly
    saves about $1/3$ of the runtime. This is more obvious for larger triangles. The following time table is taken
    from rasterizing <code>basic/test5.svg</code>:
</p>

<div align="middle">
    <table width="75%" align="middle">
        <td>
            Naive method <br/>
            <code>
                Time used with 1x1 super-sampling: 0.014821s <br/>
                Time used with 1x1 super-sampling: 0.014997s <br/>
                Time used with 1x1 super-sampling: 0.007087s <br/>
                Time used with 1x1 super-sampling: 0.006630s <br/>
                Time used with 1x1 super-sampling: 0.003994s <br/>
                Time used with 1x1 super-sampling: 0.003177s <br/>
            </code>
        </td>
        <td>
            Barycentric coordinates <br/>
            <code>
                Time used with 1x1 super-sampling: 0.009332s <br/>
                Time used with 1x1 super-sampling: 0.009665s <br/>
                Time used with 1x1 super-sampling: 0.004028s <br/>
                Time used with 1x1 super-sampling: 0.003269s <br/>
                Time used with 1x1 super-sampling: 0.002295s <br/>
                Time used with 1x1 super-sampling: 0.001488s <br/>
            </code>
        </td>
    </table>
</div>

<p>The time complexity improvement for large enough triangles is roughly 1/3.</p>


<h3 align="middle">Part 2: Antialiasing triangles</h3>

<p>
    We apply supersampling by dividing each pixel into $n \times n$ sub-pixels and apply color sampling for each
    sub-pixel. The color of the pixel is the average of the color of the $n \times n$ sub-pixels. This is helpful to
    anti-alias the picture by adding a color gradient between hard edges.
</p>

<div align="middle">
    <table width="100%" align="middle">
        <td>
            <img src="images/p2_supersampling_1.png" align="middle" style="width:100%"/>
            <figcaption align="middle">No supersampling.</figcaption>
        </td>
        <td>
            <img src="images/p2_supersampling_4.png" align="middle" style="width:100%"/>
            <figcaption align="middle">Degree 2 supersampling.</figcaption>
        </td>
        <td>
            <img src="images/p2_supersampling_16.png" align="middle" style="width:100%"/>
            <figcaption align="middle">Degree 4 supersampling.</figcaption>
        </td>
    </table>
</div>


<h3 align="middle">Part 3: Transforms</h3>

<div align="middle">
    <img src="images/p3_transforms.png" align="middle" width="30%"/>
    <figcaption align="middle">A robot running.</figcaption>
</div>

<p>
    By applying additional rotations on whole body and the limbs and adjust the amount of translation, the robot looks
    like it's running, at least it should supposedly look like it's running. This is the best I can do and what it is is
    what it is :(
</p>

<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>

<div align="middle">
    <img src="images/p4_barycentric_triangle.png" align="middle" width="30%"/>
    <figcaption align="middle">The RGB color intensity is the Barycentric coordinate w.r.t. each vertex.</figcaption>
</div>

<p> Barycentric coordinate computes the distance from a given points to each sides as we can see from the graph. </p>

<div align="middle">
    <img src="images/p4_barycentric_pallet.png" align="middle" width="30%"/>
    <figcaption align="middle">A color pallet.</figcaption>
</div>

<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

<p>
    Texture sampling is to sample the color of a given point from a texture, given the corresponding texture
    coordinates. We sample from the nearest integer coordinate if we are using the nearest method, and use linear
    interpolation if we are using the bilinear method. By linear interpolation we mean sample from the four
    integer-coordinate corners around the given point, and find a linear combination of the colors. The closer the point
    is to one of the corner, the color of the corner will have a stronger influence.
</p>

<div align="middle">
    <table width="100%" align="middle">
        <tr>
            <td>
                <img src="images/p5_nearest_1.png" align="middle" width="400px"/>
                <figcaption align="middle">Nearest, no supersampling.</figcaption>
                <br/>
            </td>
            <td>
                <img src="images/p5_nearest_16.png" align="middle" width="400px"/>
                <figcaption align="middle">Nearest, degree 4 supersampling.</figcaption>
                <br>
            </td>
        </tr>
        <br>
        <tr>
            <td>
                <img src="images/p5_bilinear_1.png" align="middle" width="400px"/>
                <figcaption align="middle">Bilinear, no supersampling.</figcaption>
            </td>
            <td>
                <img src="images/p5_bilinear_16.png" align="middle" width="400px"/>
                <figcaption align="middle">Bilinear, degree 4 supersampling.</figcaption>
            </td>
        </tr>
    </table>
</div>

<p>
    Even though we applied supersampling, rendering this picture using nearest texture sampling still have jaggies. This
    is due to the fact that the texture contains more information in 1 image pixel in this picture. <br/>

    There will be a large difference between the two methods if the scale between the image coordinate and the texture
    coordinate is far from 1:1. If the scale of the image coordinate is relatively smaller, nearest method will show
    Moire patterns and jaggies vice versa.
</p>

<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>

<p>
    Level sampling enable us to sample from textures with different precision levels. If the scale of the image
    coordinate is relatively smaller, we can sample from a lower-res texture and avoid Moire patterns. <br/>

    Using mipmap allow us to achieve coordinate-relative antialising at the cost of roughly 1/3 more memory and 4 times
    texture reading time. If we also apply linear interpolation for mipmap levels, this is 8 times texture reading time.
</p>

<div align="middle">
    <table width="100%" align="middle" style="border-spacing: 0">
        <tr>
            <td>
                <img src="images/p6_l0_pnearest.png" align="middle" style="width:100%"/>
                <figcaption align="middle"><code>L_ZERO, P_NEAREST</code></figcaption>
                <br>
            </td>
            <td>
                <img src="images/p6_lnearest_pnearest.png" align="middle" style="width:100%"/>
                <figcaption align="middle"><code>L_NEAREST, P_NEAREST</code></figcaption>
                <br>
            </td>
            <td>
                <img src="images/p6_lbilinear_pnearest.png" align="middle" style="width:100%"/>
                <figcaption align="middle"><code>L_LINEAR, P_NEAREST</code></figcaption>
                <br>
            </td>
        </tr>
        <br>
        <tr>
            <td>
                <img src="images/p6_l0_pbilinear.png" align="middle" style="width:100%"/>
                <figcaption align="middle"><code>L_ZERO, P_LINEAR</code></figcaption>
            </td>
            <td>
                <img src="images/p6_lnearest_pbilinear.png" align="middle" style="width:100%"/>
                <figcaption align="middle"><code>L_NEAREST, P_LINEAR</code></figcaption>
            </td>
            <td>
                <img src="images/p6_lbilinear_pbilinear.png" align="middle" style="width:100%"/>
                <figcaption align="middle"><code>L_LINEAR, P_LINEAR</code></figcaption>
            </td>
        </tr>
    </table>
</div>

<h2 align="middle">Section III: Art Competition</h2>

<h3 align="middle">Part 7: Draw something interesting!</h3>

<div align="middle">
    <img src="competition/nines.png" align="middle" width="60%"/>
</div>

<p>
    This is a low-poly picture of my girlfriend's cat Nines when she was a few months old, when she doesn't know that
    thing called shyness and doesn't rush to the back of the shelf if she saw me. <br/>
    The picture is created through <a href="https://snorpey.github.io/triangulation/">an online low-poly svg converting
    tool</a>. The svg file was modified through a script (<code>src/svg_convert.py</code>) that convert color values to
    parse-able hex values, remove border lines and scale to the correct size.
</p>

</body>

</html>
